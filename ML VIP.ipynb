{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf0ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: data_warehouse\\processed_sales_data.csv\n",
      "VIP cluster chosen: 1\n",
      "Written:\n",
      " - data_warehouse\\vip_sales_data.csv \n",
      " - reverse_etl\\vip_customers.csv\n",
      "\n",
      "Preview (first 10 rows):\n",
      "customer_id product_id                 sale_date  total_revenue vip_status  vip_top20pct_by_spend\n",
      "      C_001       P101 2023-01-15 00:00:00+00:00          300.0    Non-VIP                      0\n",
      "      C_002       P102 2023-01-20 00:00:00+00:00          225.0    Non-VIP                      0\n",
      "      C_003       P101 2023-01-02 00:00:00+00:00          600.0    Non-VIP                      0\n",
      "      C_004       P104 2023-05-02 00:00:00+00:00           30.0    Non-VIP                      0\n",
      "      C_005       P102 2023-10-02 00:00:00+00:00          150.0    Non-VIP                      0\n",
      "      C_006       P101 2023-02-20 00:00:00+00:00          450.0    Non-VIP                      0\n",
      "      C_008       P104 2023-01-03 00:00:00+00:00          150.0    Non-VIP                      0\n",
      "      C_009       P102 2023-05-03 00:00:00+00:00           75.0    Non-VIP                      0\n",
      "      C_001       P105 2023-10-03 00:00:00+00:00          360.0    Non-VIP                      0\n",
      "      C_010       P103 2023-03-15 00:00:00+00:00          250.5    Non-VIP                      0\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "WAREHOUSE_DIR = \"data_warehouse\"\n",
    "RAW_DIR = \"raw_data\"\n",
    "os.makedirs(WAREHOUSE_DIR, exist_ok=True)\n",
    "os.makedirs(\"reverse_etl\", exist_ok=True)\n",
    "\n",
    "POSSIBLE_SOURCES = [\n",
    "    os.path.join(WAREHOUSE_DIR, \"processed_sales_data.csv\"),\n",
    "    \"processed_sales_data.csv\",\n",
    "    os.path.join(RAW_DIR, \"sale_price.csv\"),\n",
    "]\n",
    "src_path = next((p for p in POSSIBLE_SOURCES if os.path.exists(p)), None)\n",
    "if src_path is None:\n",
    "    raise FileNotFoundError(f\"Could not find any of: {POSSIBLE_SOURCES}\")\n",
    "\n",
    "print(f\"Loading: {src_path}\")\n",
    "df = pd.read_csv(src_path)\n",
    "\n",
    "\n",
    "if \"customer_id\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'customer_id' column.\")\n",
    "\n",
    "if \"total_revenue\" not in df.columns:\n",
    "    if \"sale_price\" in df.columns:\n",
    "        x = df[\"sale_price\"].astype(str).str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        df[\"sale_price\"] = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if \"quantity\" not in df.columns:\n",
    "        df[\"quantity\"] = 1\n",
    "    df[\"total_revenue\"] = df[\"sale_price\"].fillna(0) * df[\"quantity\"]\n",
    "\n",
    "\n",
    "if \"sale_date\" in df.columns:\n",
    "    df[\"sale_date\"] = pd.to_datetime(\n",
    "        df[\"sale_date\"], errors=\"coerce\", dayfirst=True, utc=True\n",
    "    )\n",
    "else:\n",
    "    df[\"sale_date\"] = pd.NaT\n",
    "\n",
    "\n",
    "g = (\n",
    "    df.groupby(\"customer_id\", dropna=False)\n",
    "      .agg(total_spend=(\"total_revenue\", \"sum\"),\n",
    "           purchase_count=(\"total_revenue\", \"size\"),\n",
    "           last_purchase_date=(\"sale_date\", \"max\"))\n",
    "      .reset_index()\n",
    ")\n",
    "g[\"avg_order_value\"] = g[\"total_spend\"] / g[\"purchase_count\"].replace(0, np.nan)\n",
    "\n",
    "\n",
    "today = pd.Timestamp.now(tz=\"UTC\").normalize()\n",
    "g[\"recency_days\"] = (today - g[\"last_purchase_date\"]).dt.days\n",
    "\n",
    "if g[\"recency_days\"].isna().all():\n",
    "    g[\"recency_days\"] = 0\n",
    "else:\n",
    "    g[\"recency_days\"] = g[\"recency_days\"].fillna(g[\"recency_days\"].median())\n",
    "\n",
    "for c in [\"total_spend\", \"purchase_count\", \"avg_order_value\", \"recency_days\"]:\n",
    "    g[c] = g[c].fillna(0)\n",
    "\n",
    "\n",
    "feat_cols = [\"total_spend\", \"purchase_count\", \"avg_order_value\", \"recency_days\"]\n",
    "X = StandardScaler().fit_transform(g[feat_cols].to_numpy())\n",
    "kmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
    "g[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "vip_cluster = g.groupby(\"cluster\")[\"total_spend\"].mean().idxmax()\n",
    "g[\"vip_status\"] = np.where(g[\"cluster\"] == vip_cluster, \"VIP\", \"Non-VIP\")\n",
    "\n",
    "q80 = g[\"total_spend\"].quantile(0.80)\n",
    "g[\"vip_top20pct_by_spend\"] = (g[\"total_spend\"] >= q80).astype(int)\n",
    "\n",
    "\n",
    "enriched = df.merge(\n",
    "    g[[\"customer_id\", \"vip_status\", \"vip_top20pct_by_spend\"]],\n",
    "    on=\"customer_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "row_out  = os.path.join(WAREHOUSE_DIR, \"vip_sales_data.csv\")\n",
    "cust_out = os.path.join(\"reverse_etl\", \"vip_customers.csv\")\n",
    "enriched.to_csv(row_out, index=False)\n",
    "g.sort_values(\"total_spend\", ascending=False).to_csv(cust_out, index=False)\n",
    "\n",
    "print(\"VIP cluster chosen:\", vip_cluster)\n",
    "print(\"Written:\\n -\", row_out, \"\\n -\", cust_out)\n",
    "\n",
    "peek_cols = [c for c in [\"customer_id\",\"product_id\",\"sale_date\",\"total_revenue\",\"vip_status\",\"vip_top20pct_by_spend\"] if c in enriched.columns]\n",
    "print(\"\\nPreview (first 10 rows):\")\n",
    "print(enriched.head(10)[peek_cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e84d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
